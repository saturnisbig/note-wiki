# Python爬虫框架概述

整理上周笔记及制定本周计划
2017-05-22 06:33:29 - 2017-05-22 07:03:31 

学习博文
2017-05-22 07:03:23 - 2017-05-22 07:26:25
作者建议先熟悉现有框架，了解其涉及理念（阅读源码等），后期熟悉后可根据
自身需要做一些个性化的设计。

scrapy组成：

Scrapy引擎：处理整个系统的数据流，触发事物（核心）；
调度器（Scheduler）：接受引擎发来的请求，压入队列，在引擎请求时返回，可以
想象成URL的队列，用它决定下一个要抓取的网址是什么，去重；
Downloader(下载器)：下载网页内容给爬虫(Spider)，下载器是建立在twisted这个
高效的异步模型上的；
Spider(爬虫)：主要干活的，从特定网页提取信息，即Item，也可提取链接，让
Scrapy继续抓取；
Pipeline(项目管道)：处理爬虫从网页提取的信息（Item，实体），主要功能是持久化，
验证实体有效性，清除多余信息，当页面被爬虫解析后，将发送到项目管道，经过
特定次序处理数据；
Downloader Middlewares(下载中间件)：处理scrapy引擎和下载器之间的请求；
Spider Middlewares(爬虫中间件)：处理Spider的输入响应和输出请求；
Scheduler Middlewares(调度中间件)：处理scrapy引擎发送到调度的请求和响应。

运行的顺序：
引擎从调度器取一个URL用于抓取；
引擎把URL封装称Request请求，传给下载器下载，并封装成响应包；
爬虫解析响应；
若是解析出Item则交给管道进一步处理；解析出URL则交给调度器等待抓取。





